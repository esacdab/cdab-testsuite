{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the provider, one of 'CREODIAS', 'MUNDI', 'ONDA' and 'SOBLOO'\n",
    "provider = 'SOBLOO'\n",
    "\n",
    "# Specific settings for SOBLOO\n",
    "sobloo_api_key = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input definition\n",
    "\n",
    "Define the area of interest (as WKT) and the identifiers of the pre- and post-event Sentinel-2 products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_wkt = 'POLYGON((-7.693 40.103,-7.237 40.103,-7.237 40.399,-7.693 40.399,-7.693 40.103))'\n",
    "\n",
    "input_identifiers = ('S2A_MSIL2A_20201026T112151_N0214_R037_T29TPE_20201027T144218',\n",
    "                     'S2B_MSIL2A_20201130T112429_N0214_R037_T29TPE_20201130T131854')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data path\n",
    "\n",
    "This path defines where the data is staged in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/workspace/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "This imports all the necessary python packages. Misconfigurations in the python environment can easily lead to problems. Pay particular attention to the **PREFIX** environment variable (the base path of the conda environment), which sets many other paths. It may be necessary that you have to create a new environment based on the environment file in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PREFIX'] = '/opt/anaconda/envs/env_burned_area/'\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['PREFIX'], 'conda-otb/lib/python'))\n",
    "os.environ['OTB_APPLICATION_PATH'] = os.path.join(os.environ['PREFIX'], 'conda-otb/lib/otb/applications')\n",
    "os.environ['GDAL_DATA'] =  os.path.join(os.environ['PREFIX'], 'share/gdal')\n",
    "os.environ['PROJ_LIB'] = os.path.join(os.environ['PREFIX'], 'share/proj')\n",
    "os.environ['GPT_BIN'] = os.path.join(os.environ['PREFIX'], 'snap/bin/gpt')\n",
    "os.environ['_JAVA_OPTIONS'] = '-Xms1g -Xmx1g'\n",
    "\n",
    "import otbApplication\n",
    "import gdal\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import box, shape, mapping\n",
    "from shapely.errors import ReadingError\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "gdal.UseExceptions()\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data download\n",
    "\n",
    "Execute the appropriate cell according to the value of `provider`.\n",
    "\n",
    "At the end of the output, the total duration of the data download is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for SOBLOO\n",
    "url_regex = re.compile('.*\\.SAFE(/(?P<dir>[^\\?]*))?(/(?P<file>[^/\\?]+))(\\?.*)?')\n",
    "\n",
    "if provider == 'SOBLOO':\n",
    "    time_start = datetime.utcnow()\n",
    "    for id in input_identifiers:\n",
    "        print(\"Product: {0}\".format(id))\n",
    "        response = requests.post(\"https://sobloo.eu/api/v1-beta/direct-data/product-links\",\n",
    "                          headers = {'Authorization': 'Apikey {0}'.format(sobloo_api_key)},\n",
    "                          json={'product': id, \"regexp\": \".*(B0[238]|B8A|B1[12]|manifest).*\"}\n",
    "                         )\n",
    "        \n",
    "        result = json.loads(response.text)\n",
    "        \n",
    "        download_list = [ l['url'] for l in result['links'] ]\n",
    "        for url in download_list:\n",
    "            m = url_regex.match(url)\n",
    "            if not m:\n",
    "                raise('Unrecognised URL pattern: {0}'.format(url))\n",
    "\n",
    "            file_dir = \"{0}/{0}.SAFE/{1}\".format(id, m.group('dir'))\n",
    "            file_name = m.group('file')\n",
    "            if not file_dir:\n",
    "                file_dir = ''\n",
    "\n",
    "            print(\"- Downloading {0}\".format(file_name))\n",
    "            Path(\"{0}/{1}\".format(data_path, file_dir)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            location = \"{0}/{1}/{2}\".format(data_path, file_dir, file_name)\n",
    "            r = requests.get(url, stream=True)\n",
    "            #with open(location, 'wb') as f:\n",
    "            #    for chunk in r.iter_content(chunk_size=8192): \n",
    "            #        f.write(chunk)\n",
    "            #r.close()\n",
    "\n",
    "    time_end = datetime.utcnow()\n",
    "    \n",
    "    print(\"Download duration: {0} seconds\".format(round((time_end - time_start).total_seconds(), 3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain metadata\n",
    "\n",
    "Extract the metadata of the input products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as etree\n",
    "\n",
    "namespaces = {\n",
    "    'xfdu': 'urn:ccsds:schema:xfdu:1',\n",
    "    'safe': 'http://www.esa.int/safe/sentinel/1.1',\n",
    "    'gml': 'http://www.opengis.net/gml',\n",
    "}\n",
    "\n",
    "metadata = []\n",
    "\n",
    "for id in input_identifiers:\n",
    "    with open('{0}/{1}/{1}.SAFE/manifest.safe'.format(data_path, id), 'rb') as manifest:\n",
    "        manifest_xml = etree.fromstring(manifest.read())\n",
    "\n",
    "    metadata_elem = manifest_xml.xpath('/xfdu:XFDU/metadataSection', namespaces=namespaces)[0]\n",
    "\n",
    "    startdate = metadata_elem.xpath('metadataObject/metadataWrap/xmlData/safe:acquisitionPeriod/safe:startTime', namespaces=namespaces)[0].text\n",
    "    enddate = startdate\n",
    "    orbitDirection = metadata_elem.xpath('metadataObject/metadataWrap/xmlData/safe:orbitReference/safe:orbitNumber', namespaces=namespaces)[0].get('groundTrackDirection').upper()\n",
    "    coordinates = metadata_elem.xpath('metadataObject/metadataWrap/xmlData/safe:frameSet/safe:footPrint/gml:coordinates', namespaces=namespaces)[0].text.split(' ')\n",
    "    wkt = []\n",
    "    for i in range(len(coordinates) // 2):\n",
    "        wkt.append(\"{0} {1}\".format(coordinates[2 * i + 1], coordinates[2 * i]))\n",
    "\n",
    "    metadata.append(\n",
    "        {\n",
    "            'identifier': id,\n",
    "            'startdate': startdate,\n",
    "            'enddate': enddate,\n",
    "            'orbitDirection': orbitDirection,\n",
    "            'wkt': 'POLYGON(({0}))'.format(','.join(wkt))\n",
    "        }\n",
    "    )\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in metadata:\n",
    "    row['wkt'] = loads(row['wkt'])\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = loads(aoi_wkt)\n",
    "(min_lon, min_lat, max_lon, max_lat) = aoi.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aoi)\n",
    "print (isinstance(aoi, str))\n",
    "for row in metadata:\n",
    "    ext = analyse(row, aoi, data_path)\n",
    "    \n",
    "for row in metadata:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composites = []\n",
    "\n",
    "bands = ['B12', 'B11', 'B8A']\n",
    "\n",
    "for row in metadata:\n",
    "    vrt_bands = []\n",
    "    \n",
    "    for j, band in enumerate(bands):\n",
    "        \n",
    "        vrt_bands.append(get_band_path(row, band))\n",
    "    \n",
    "    vrt = '{0}.vrt'.format(row['identifier'])\n",
    "    ds = gdal.BuildVRT(vrt,\n",
    "                       vrt_bands,\n",
    "                       srcNodata=0,\n",
    "                       xRes=10, \n",
    "                       yRes=10,\n",
    "                       separate=True)\n",
    "    ds.FlushCache()\n",
    "    \n",
    "    tif =  '{0}.tif'.format(row['identifier'])\n",
    "    \n",
    "    if aoi is None:\n",
    "        gdal.Translate(tif,\n",
    "                       vrt,\n",
    "                       outputType=gdal.GDT_Byte, \n",
    "                       scaleParams=[[0, 10000, 0, 255]])\n",
    "    else:\n",
    "        gdal.Translate(tif,\n",
    "                       vrt,\n",
    "                       projWin=[min_lon, max_lat, max_lon, min_lat],\n",
    "                       projWinSRS='EPSG:4326',\n",
    "                       outputType=gdal.GDT_Byte, \n",
    "                       scaleParams=[[0, 10000, 0, 255]])\n",
    "        \n",
    "        \n",
    "        \n",
    "    tif_e =  '{0}_NIR_SWIR_COMPOSITE.tif'.format(row['identifier'])\n",
    "    \n",
    "    try:\n",
    "        contrast_enhancement(tif, tif_e)\n",
    "\n",
    "        composites.append(tif_e)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "    \n",
    "    # os.remove(tif)\n",
    "    # os.remove(vrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['B8A', 'B12']\n",
    "\n",
    "composites = []\n",
    "\n",
    "for row in metadata:\n",
    "        \n",
    "    vrt_bands = []\n",
    "    \n",
    "    for j, band in enumerate(bands):\n",
    "        \n",
    "        vrt_bands.append(get_band_path(row, band))\n",
    "    \n",
    "    vrt = '{0}.vrt'.format(row['identifier'])\n",
    "    ds = gdal.BuildVRT(vrt,\n",
    "                       vrt_bands,\n",
    "                       srcNodata=0,\n",
    "                       xRes=20, \n",
    "                       yRes=20,\n",
    "                       separate=True)\n",
    "    ds.FlushCache()\n",
    "    \n",
    "    tif =  '{0}.tif'.format(row['identifier'])\n",
    "    \n",
    "    if aoi is not None:\n",
    "        gdal.Translate(tif,\n",
    "                       vrt,\n",
    "                       projWin=[min_lon, max_lat, max_lon, min_lat],\n",
    "                       projWinSRS='EPSG:4326',\n",
    "                       outputType=gdal.GDT_Float32)\n",
    "    else:\n",
    "        \n",
    "        gdal.Translate(tif,\n",
    "                       vrt,\n",
    "                       outputType=gdal.GDT_Float32)\n",
    "        \n",
    "    \n",
    "    hot_spot(get_band_path(row, 'B8A'),\n",
    "             get_band_path(row, 'B12'),\n",
    "             '{0}_HOT_SPOT.tif'.format(row['identifier']))\n",
    "    \n",
    "    # os.remove(tif)\n",
    "    # os.remove(vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in metadata:\n",
    "    \n",
    "    hot_spot(get_band_path(row, 'B8A'),\n",
    "             get_band_path(row, 'B12'),\n",
    "             '{0}_HOT_SPOT.tif'.format(row['identifier']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed = []\n",
    "\n",
    "resample = dict()\n",
    "resample['referenceBandName'] = 'B2'\n",
    "\n",
    "reproject = dict()\n",
    "reproject['crs'] = 'EPSG:4326'\n",
    "\n",
    "subset = dict()\n",
    "subset['geoRegion'] = box(*aoi.bounds).wkt\n",
    "subset['copyMetadata'] = 'true'\n",
    "\n",
    "bands = '''<targetBands>\n",
    "    <targetBand>\n",
    "      <name>NDWI</name>\n",
    "      <type>float32</type>\n",
    "      <expression>(B3 - B8) / (B3 + B8)</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    <targetBand>\n",
    "      <name>NBR</name>\n",
    "      <type>float32</type>\n",
    "      <expression>(B8 - B12) / (B8 + B12)</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    <targetBand>\n",
    "      <name>valid_pixels</name>\n",
    "      <type>float32</type>\n",
    "      <expression>scl_vegetation or scl_not_vegetated ? 1 : 0</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    </targetBands>'''\n",
    "\n",
    "band_maths = dict()\n",
    "band_maths['targetBandDescriptors'] = bands \n",
    "\n",
    "\n",
    "\n",
    "for row in metadata:\n",
    "    print(os.path.join(row['local_path'], row['identifier'] + '.SAFE', 'MTD_MSIL2A.xml'))\n",
    "    \n",
    "    read = dict()\n",
    "    read['file'] = os.path.join(row['local_path'], row['identifier'] + '.SAFE', 'MTD_MSIL2A.xml') #, 'manifest.safe')\n",
    "    #read['formatName'] = 'SENTINEL-2-MSI-MultiRes-UTM52N'\n",
    "    \n",
    "    write = dict()\n",
    "    write['file'] = 'pre_{}'.format(row['identifier'])\n",
    "\n",
    "    row['pre_proc'] = 'pre_{}'.format(row['identifier'])\n",
    "    \n",
    "    \n",
    "    pre_processed.append('pre_{}'.format(row['identifier']))\n",
    "\n",
    "    print(\"*******\")\n",
    "    print(\"IDENTIFIER = {0}\".format(row['identifier']))\n",
    "    print(\"READ = {0}\".format(read))\n",
    "    print(\"WRITE = {0}\".format(write))\n",
    "    print(\"*******\")\n",
    "    \n",
    "    \n",
    "    pre_processing(Read=read, \n",
    "                 Resample=resample, \n",
    "                 Reproject=reproject, \n",
    "                 Subset=subset,\n",
    "                 BandMaths=band_maths,\n",
    "                 Write=write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path = \"{0}.dim\".format(min((r['pre_proc'] for r in metadata)))\n",
    "slave_path = \"{0}.dim\".format(max((r['pre_proc'] for r in metadata)))\n",
    "\n",
    "print(master_path)\n",
    "print(slave_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = GraphProcessor(os.path.join(os.environ['PREFIX'], 'snap/bin/gpt'))\n",
    "operator = 'Read'\n",
    "\n",
    "node_id = 'Read_M'\n",
    "\n",
    "source_node_id = ''\n",
    "\n",
    "parameters = get_operator_default_parameters(operator)\n",
    "     \n",
    "parameters['file'] = master_path \n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "\n",
    "operator = 'Read'\n",
    "\n",
    "node_id = 'Read_S'\n",
    "\n",
    "source_node_id = ''\n",
    "\n",
    "parameters = get_operator_default_parameters(operator)\n",
    "     \n",
    "parameters['file'] = slave_path   \n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "\n",
    "operator = 'Collocate'\n",
    "\n",
    "parameters = get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['masterComponentPattern'] = 'PRE_FIRE_${ORIGINAL_NAME}'\n",
    "parameters['slaveComponentPattern'] = 'POST_FIRE_${ORIGINAL_NAME}'\n",
    "\n",
    "source_node_id = dict()\n",
    "\n",
    "source_node_id['master'] = 'Read_M'\n",
    "\n",
    "source_node_id['slave'] = 'Read_S'\n",
    "\n",
    "\n",
    "node_id = 'Collocate'\n",
    "\n",
    "mygraph.add_node(operator, operator,  parameters, source_node_id)\n",
    "\n",
    "operator = 'Write'\n",
    "\n",
    "node_id = 'Write'\n",
    "\n",
    "source_node_id = 'Collocate'\n",
    "\n",
    "\n",
    "\n",
    "parameters = get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['file'] = 'collocated'\n",
    "parameters['formatName'] = 'BEAM-DIMAP'\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = 'burned_area_{0}_{1}'.format(datetime.strptime(max(r['enddate'] for r in metadata)[:19] , '%Y-%m-%dT%H:%M:%S').strftime('%Y%m%d_%H%M%S'),\n",
    "                                          datetime.strptime(max(r['enddate'] for r in metadata)[:19] , '%Y-%m-%dT%H:%M:%S').strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocated_input = 'collocated.dim'\n",
    "\n",
    "read = dict()\n",
    "read['file'] = collocated_input\n",
    "\n",
    "bands = '''<targetBands>\n",
    "    <targetBand>\n",
    "      <name>dNBR</name>\n",
    "      <type>float32</type>\n",
    "      <expression>(PRE_FIRE_valid_pixels == 1 and POST_FIRE_valid_pixels == 1 and ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) > 0.27) ? PRE_FIRE_NBR - POST_FIRE_NBR : -999</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    <targetBand>\n",
    "      <name>RBR</name>\n",
    "      <type>float32</type>\n",
    "      <expression>(PRE_FIRE_valid_pixels == 1 and POST_FIRE_valid_pixels == 1 and ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) > 0.27) ? ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) : -999</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    <targetBand>\n",
    "      <name>valid_pixels</name>\n",
    "      <type>float32</type>\n",
    "      <expression>PRE_FIRE_valid_pixels == 1 and POST_FIRE_valid_pixels == 1</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    </targetBands>'''\n",
    "\n",
    "band_maths = dict()\n",
    "band_maths['targetBandDescriptors'] = bands \n",
    "\n",
    "write = dict()\n",
    "write['file'] = output_name\n",
    "write['formatName'] = 'GeoTIFF'\n",
    "\n",
    "burned_area(Read=read, \n",
    "            BandMaths=band_maths,\n",
    "            Write=write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_names = ['dNBR',\n",
    "              'RBR',\n",
    "             'valid_pixels']\n",
    "\n",
    "expressions = ['PRE_FIRE_NDWI >= 0.0 ? 0 : ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) > 0.27 ? PRE_FIRE_NBR - POST_FIRE_NBR : 0',\n",
    "               'PRE_FIRE_NDWI >= 0.0 ? 0 : ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) > 0.27 ? ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) : 0',\n",
    "              'PRE_FIRE_valid_pixels == 1 and POST_FIRE_valid_pixels == 1']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ds_temp = gdal.Open(output_name + '.tif',  gdal.OF_UPDATE)\n",
    "\n",
    "for band_index in range(ds_temp.RasterCount):\n",
    "\n",
    "    band_metadata = dict()\n",
    "    band_metadata['BAND_EXPRESSION'] = expressions[band_index]\n",
    "\n",
    "    src_band = ds_temp.GetRasterBand(band_index+1)\n",
    "    src_band.SetMetadata(band_metadata)\n",
    "    src_band.SetDescription(band_names[band_index])  \n",
    "\n",
    "ds_temp.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_threshold = 0.270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_palette = {-999: [0, 0, 0, 255],\n",
    "                    -1: [159, 159, 159, 0], # grey\n",
    "                    -0.5: [43, 25, 223, 0], # blue\n",
    "                    -0.251: [139, 221, 231, 0], # cyan\n",
    "                    -0.101: [97, 169, 45, 255], # unburned, green \n",
    "                    0.099: [250, 254, 76, 0], # yellow\n",
    "                    0.269: [228, 173, 55, 0], # orange\n",
    "                    0.439: [202, 59, 18, 0],  # red\n",
    "                    0.659: [85, 15, 112, 0]} # purple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster2rgb(output_name + '.tif',\n",
    "           severity_palette,\n",
    "           output_name + '.rgb.tif',\n",
    "           raster_band=1,\n",
    "           discrete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dimap in ['collocated'] + [r['pre_proc'] for r in metadata]:\n",
    "    print(\"Delete {0}.dim\".format(dimap))\n",
    "    os.remove(dimap + '.dim')\n",
    "    print(\"Delete {0}.data\".format(dimap))\n",
    "    shutil.rmtree(dimap + '.data') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_ewf_burned_area]",
   "language": "python",
   "name": "conda-env-env_ewf_burned_area-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
